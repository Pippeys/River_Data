{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib as url\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# Load table of locations and Ids's\n",
    "Ref = pd.read_csv('C:/Users/Scott/Desktop/Projects/River_Data/RiverReferenceTable.csv',\n",
    "                    dtype={'WaterDischarge': str, 'PHLevel': str,'WaterTemp': str})\n",
    "sites = Ref.USGS_ID.tolist()\n",
    "string = ''\n",
    "\n",
    "for i in sites:\n",
    "    string = string+','+str(i)\n",
    "sites=string[1:]\n",
    "\n",
    "# Metrics to load from stations\n",
    "# 00060 = discharge\n",
    "# 00400 = PH level\n",
    "# 00010 = water temperature\n",
    "parameters = '00060'+','+'00400'+','+'00010'\n",
    "\n",
    "# URL to load json of data \n",
    "# Use format=rmd for readable URL\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+\n",
    "        sites+'&period=P20D&parameterCd='+\n",
    "        parameters)\n",
    "r=requests.get(link)\n",
    "data = json.loads(r.text)\n",
    "\n",
    "#Create empty DataFrame with columns\n",
    "water = pd.DataFrame(columns=['Name','VariableDescription','Value','DateTime'])\n",
    "\n",
    "i=0\n",
    "for items in data['value']['timeSeries']:\n",
    "    for name in items['sourceInfo']:\n",
    "        if name == 'siteName':\n",
    "            # Station name\n",
    "            names = items['sourceInfo'][name]\n",
    "    for name in items:\n",
    "         if name == 'variable':\n",
    "            # Parameter Description \n",
    "            var = items[name]['variableDescription']\n",
    "    for values in items['values']:\n",
    "        for v in values['value']:\n",
    "            # Append values for each column\n",
    "            water.loc[i] = [names,var,v['value'],v['dateTime']]\n",
    "            i=1+i\n",
    "\n",
    "\n",
    "# Break apart Date and Time\n",
    "dates = [date[0:10] for date in water.DateTime]\n",
    "times = [time[11:16] for time in water.DateTime]\n",
    "water['DateTime'] = pd.to_datetime(pd.Series(dates)+' '+pd.Series(times))\n",
    "water.Value = water.Value.astype(float)\n",
    "waterpp = water.pivot_table(\n",
    "                    index='DateTime',\n",
    "                    columns=['VariableDescription','Name'],\n",
    "                    values=['Value'])\n",
    "water.VariableDescription.loc[\n",
    "    water.VariableDescription == 'Discharge, cubic feet per second'] = 'Discharge'\n",
    "water.VariableDescription.loc[\n",
    "    water.VariableDescription == 'Temperature, water, degrees Celsius'] = 'Temperature'\n",
    "water.VariableDescription.loc[\n",
    "    water.VariableDescription =='pH, water, unfiltered, field, standard units' ] = 'pH'\n",
    "water = water.sort_values(['Name','VariableDescription','DateTime'])\n",
    "\n",
    "dts = pd.Series(pd.to_datetime(water.DateTime.astype(np.int64).groupby(np.arange(len(water))//16).mean()))\n",
    "vals = pd.Series((water.Value.groupby(np.arange(len(water))//16).mean()))\n",
    "ind = pd.Series((pd.Series(water.index).groupby(np.arange(len(water))//16).mean()).astype(int))\n",
    "df = pd.concat([dts,vals,ind],axis=1)\n",
    "info = water[['Name','VariableDescription']]\n",
    "df = pd.merge(df,info,\n",
    "              left_on=df[0],\n",
    "              right_on=info.index,how='left')\n",
    "df = df.drop(columns=['key_0',0])\n",
    "\n",
    "full_df = pd.read_csv('CurrentWater.csv')\n",
    "full_df = full_df.append(df)\n",
    "full_df = full_df[['DateTime','Value','Name','VariableDescription']]\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "full_df[['DateTime','Value','Name','VariableDescription']].to_csv('CurrentWater.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 2022-03-15\n",
      "Russian River HaciendaBridge  Zip Codes\n",
      "95436   95436\n",
      "Navarro River  Zip Codes\n",
      "95432   95432\n",
      "Noyo River  Zip Codes\n",
      "95437   95437\n",
      "San Lorenzo River Upper  Zip Codes\n",
      "95018   95018\n",
      "Mad River  Zip Codes\n",
      "95573   95573\n",
      "Putah Creek  Zip Codes\n",
      "95694   95694\n",
      "Truckee River Farad  Zip Codes\n",
      "96161   96161\n",
      "Little Truckee River  Zip Codes\n",
      "96161   96161\n",
      "Smith River CC  Zip Codes\n",
      "95531   95531\n",
      "Smith River Fort Dick  Zip Codes\n",
      "95531   95531\n",
      "Eel River Fort Seward  Zip Codes\n",
      "95542   95542\n",
      "Eel River Scotia  Zip Codes\n",
      "95565   95565\n",
      "Eel River Fernbridge  Zip Codes\n",
      "95540   95540\n",
      "San Lorenzo River  Zip Codes\n",
      "95018   95018\n",
      "Hat Creek  Zip Codes\n",
      "96013   96013\n",
      "Yuba River  Zip Codes\n",
      "95944   95944\n",
      "North Fork American River  Zip Codes\n",
      "95603   95603\n",
      "Pit River  Zip Codes\n",
      "96051   96051\n",
      "East Walker  Zip Codes\n",
      "93517   93517\n",
      "East Fork Carson  Zip Codes\n",
      "96120   96120\n",
      "Trinity River Lewiston  Zip Codes\n",
      "96052   96052\n",
      "Trinity River Junction City  Zip Codes\n",
      "96048   96048\n",
      "Rogue River Grants Pass  Zip Codes\n",
      "97526   97526\n",
      "Rogue River Agness  Zip Codes\n",
      "97532   97532\n",
      "Nestucca River Beaver  Zip Codes\n",
      "97112   97112\n",
      "Redwood Creek Orick  Zip Codes\n",
      "95546   95546\n",
      "No data available at this Zip Code:  95546\n",
      "Van Duzen River Bridgeville  Zip Codes\n",
      "95526   95526\n",
      "Mattole River Ettersburg  Zip Codes\n",
      "95542   95542\n",
      "Mattole River Petrolia  Zip Codes\n",
      "95565   95565\n",
      "Trinity River Burnt Ranch  Zip Codes\n",
      "95563   95563\n",
      "North Umpqua River Winchester  Zip Codes\n",
      "97471   97471\n",
      "North Umpquar River Idlelyd  Zip Codes\n",
      "97447   97447\n",
      "Umpqua River Elkton  Zip Codes\n",
      "97436   97436\n",
      "Yuba River Marysville  Zip Codes\n",
      "95901   95901\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/getting-weather-data-in-3-easy-steps-8dc10cc5c859\n",
    "# https://www.ncdc.noaa.gov/cdo-web/webservices/v2#data\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,date, timedelta\n",
    "\n",
    "Token = 'ziLDJecqBlvTSNGOzOmPPLmBZtXSfBwR'\n",
    "\n",
    "referencedata = pd.read_csv('C:/Users/Scott/Desktop/Projects/River_Data/RiverReferenceTable.csv')\n",
    "referencedata['ZipCode2'] = referencedata['ZipCode'].fillna(0).astype(int)\n",
    "today = date.today()\n",
    "Dateslist = [today - timedelta(days = day) for day in range(100)]\n",
    "startdate = min(Dateslist)\n",
    "enddate = max(Dateslist)\n",
    "print(startdate,enddate)\n",
    "all_data = pd.read_csv('CurrentPrecip.csv',index_col=0).drop_duplicates()\n",
    "\n",
    "for row in range(0,len(referencedata)):\n",
    "    print(referencedata.Name[row],' Zip Codes')\n",
    "    name = referencedata.Name[row]\n",
    "    zipcode = referencedata.ZipCode[row]\n",
    "    zipcode2 = referencedata.ZipCode2[row]\n",
    "    print(zipcode,' ',zipcode2)\n",
    "\n",
    "\n",
    "    data_url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&units=metric&limit=100&locationid=ZIP:'+str(zipcode)+'&startdate='+str(startdate)+'&enddate='+str(enddate)\n",
    "    \n",
    "    r = requests.get(data_url, headers={'token':Token})\n",
    "    d = json.loads(r.text)\n",
    "\n",
    "    # print(json.dumps(d, indent=4, sort_keys=True))\n",
    " \n",
    "    if len(d) == 0:\n",
    "        data_url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=100&locationid=ZIP:'+str(zipcode2)+'&startdate='+str(startdate)+'&enddate='+str(enddate)\n",
    "        r = requests.get(data_url, headers={'token':Token})\n",
    "        d = json.loads(r.text)\n",
    "\n",
    "    dates = []\n",
    "    precips = []\n",
    "\n",
    "    #get all items in the response which are precipitation readings\n",
    "    try:\n",
    "        precip = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "        precips += [item['value'] for item in precip]\n",
    "        dates += [item['date'] for item in precip]\n",
    "    except KeyError:\n",
    "        print('No data available at this Zip Code: ',zipcode2)\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Date'] = [datetime.strptime(d, '%Y-%m-%dT%H:%M:%S') for d in dates]\n",
    "    if len(precips) > 0:\n",
    "        df['Precip'] = [v for v in precips]\n",
    "\n",
    "    df['Name'] = name\n",
    "    all_data = all_data.append(df,ignore_index=True)\n",
    "# print(all_data)\n",
    "all_data.to_csv('C:/Users/Scott/Desktop/Projects/River_Data/CurrentPrecip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'resultset': {'offset': 1, 'count': 6, 'limit': 100}},\n",
       " 'results': [{'date': '2022-03-01T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 0},\n",
       "  {'date': '2022-03-02T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 0},\n",
       "  {'date': '2022-03-03T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 0},\n",
       "  {'date': '2022-03-04T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 3},\n",
       "  {'date': '2022-03-05T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 3},\n",
       "  {'date': '2022-03-06T00:00:00',\n",
       "   'datatype': 'PRCP',\n",
       "   'station': 'GHCND:US1CAYB0003',\n",
       "   'attributes': ',,N,',\n",
       "   'value': 5}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=100&locationid=ZIP:'+str(zipcode2)+'&startdate='+'2022-03-01'+'&enddate='+'2022-03-14'#str(enddate)\n",
    "r = requests.get(data_url, headers={'token':Token})\n",
    "d = json.loads(r.text)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aacbe4dc33ac>:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LightRain'] = df.shortForecast.apply(lambda x: LightRain(x))\n",
      "<ipython-input-3-aacbe4dc33ac>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Rain'] = df.shortForecast.apply(lambda x: Rain(x))\n",
      "<ipython-input-3-aacbe4dc33ac>:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HeavyRain'] = df.shortForecast.apply(lambda x: HeavyRain(x))\n",
      "<ipython-input-3-aacbe4dc33ac>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['WindMph'] = df.windSpeed.apply(lambda x: WindTranslate(x))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "# Parameters\n",
    "rivers_reference = pd.read_csv('RiverReferenceTable.csv')\n",
    "\n",
    "sites = rivers_reference.USGS_ID.tolist()\n",
    "string = ''\n",
    "\n",
    "for i in sites:\n",
    "    string = string+','+str(i)\n",
    "sites=string[1:]\n",
    "\n",
    "# URL to load json of data \n",
    "# Use format=rmd for readable URL\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+sites)\n",
    "r=requests.get(link)\n",
    "Geodata = json.loads(r.text)\n",
    "\n",
    "Forecast_df = pd.DataFrame()\n",
    "\n",
    "# Gather information from API\n",
    "for i in range(len(Geodata['value']['timeSeries'])):\n",
    "    lat = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['latitude'])\n",
    "    long = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['longitude'])\n",
    "    baseStation = Geodata['value']['timeSeries'][i]['sourceInfo']['siteName']\n",
    "    # Search API for Lat Long Position\n",
    "    r = requests.get('https://api.weather.gov/points/'+lat+','+long)\n",
    "    json_data = r.json()\n",
    "\n",
    "    # Retrieve Forecast for Lat Long Position\n",
    "    forecast_json = requests.get(json_data['properties']['forecast']).json()\n",
    "    try: \n",
    "        if forecast_json['status'] == 500:\n",
    "            continue\n",
    "    except:\n",
    "        KeyError\n",
    "    forecast = forecast_json['properties']['periods']\n",
    "    Forecast_df_temp = pd.DataFrame(forecast).drop(columns='number')\n",
    "    Forecast_df_temp['Lat'] = lat\n",
    "    Forecast_df_temp['Long'] = long\n",
    "\n",
    "    Forecast_df_temp['Station'] = baseStation\n",
    "    Forecast_df = Forecast_df.append(Forecast_df_temp,ignore_index=True)\n",
    "\n",
    "# Cleaning DataFrame\n",
    "df = Forecast_df.drop_duplicates()\n",
    "df.startTime = pd.to_datetime(df.startTime,utc=True)\n",
    "df.endTime = pd.to_datetime(df.endTime,utc=True)\n",
    "df.drop(columns=['temperatureTrend','icon'],inplace=True)\n",
    "\n",
    "# Functions for Rain types\n",
    "def LightRain(s):\n",
    "    if re.search('Slight Chance Rain',s):\n",
    "        value = 1\n",
    "    elif re.search('Light Rain',s):\n",
    "        value = 1  \n",
    "    else: value = 0\n",
    "    return value\n",
    "\n",
    "def Rain(s):\n",
    "    if re.search('Rain Showers',s):\n",
    "        value = 1\n",
    "    else: value = 0\n",
    "    return value\n",
    "\n",
    "def HeavyRain(s):\n",
    "    if re.search('Heavy Rain',s):\n",
    "        value = 1\n",
    "    else: value = 0\n",
    "    return value\n",
    "\n",
    "def WindTranslate(s):\n",
    "    s = ' '+s\n",
    "    l = len(s)-4\n",
    "    value = s[l-2:l]\n",
    "    return int(value)\n",
    "    \n",
    "# Create Rain Boolean Features\n",
    "df['LightRain'] = df.shortForecast.apply(lambda x: LightRain(x))\n",
    "df['Rain'] = df.shortForecast.apply(lambda x: Rain(x))\n",
    "df['HeavyRain'] = df.shortForecast.apply(lambda x: HeavyRain(x))\n",
    "df['WindMph'] = df.windSpeed.apply(lambda x: WindTranslate(x))\n",
    "\n",
    "# Create final Dataframe with Key\n",
    "WeatherForecast = df[['Station','name','startTime','endTime','temperature','windDirection','WindMph','LightRain','Rain','HeavyRain']]\n",
    "WeatherForecast = WeatherForecast.set_index('Station').join(rivers_reference[['USGS Name','Name']].set_index('USGS Name'))\n",
    "WeatherForecast = WeatherForecast.reset_index().rename(columns={'index':'Station','Name':'StationName'})\n",
    "WeatherForecast['Date_Name'] = WeatherForecast.startTime.dt.date.astype(str)+'_'+WeatherForecast.StationName\n",
    "\n",
    "# WeatherForecast.to_csv('WeatherForecast.csv',index=False)\n",
    "full_df = pd.read_csv('WeatherForecast.csv')\n",
    "full_df.append(WeatherForecast).drop_duplicates()[['Station','name','startTime','endTime','temperature','windDirection','WindMph','LightRain','Rain','HeavyRain','StationName','Date_Name']].to_csv('WeatherForecast.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3be916c8906cb20ccab44435c6b99f1f225b5db288434102dd7813211aeed2a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
