{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSSIAN R A HACIENDA BRIDGE NR GUERNEVILLE CA\n",
      "number of stations:  77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "# Parameters\n",
    "startDate = '2022-01-01'\n",
    "endDate = '2022-01-17'\n",
    "\n",
    "rivers_reference = pd.read_csv('C:/Users/Scott/Desktop/Projects/River_Data/RiverReferenceTable.csv')\n",
    "\n",
    "sites = rivers_reference.USGS_ID.tolist()\n",
    "string = ''\n",
    "\n",
    "for i in sites:\n",
    "    string = string+','+str(i)\n",
    "sites=string[1:]\n",
    "\n",
    "# URL to load json of data \n",
    "# Use format=rmd for readable URL\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+sites)\n",
    "r=requests.get(link)\n",
    "Geodata = json.loads(r.text)\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+sites)\n",
    "r=requests.get(link)\n",
    "Geodata = json.loads(r.text)\n",
    "\n",
    "meta = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "for i in range(1):# range(len(rivers_reference)):\n",
    "    lat = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['latitude'])\n",
    "    long = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['longitude'])\n",
    "    baseStation = Geodata['value']['timeSeries'][i]['sourceInfo']['siteName']\n",
    "    # Search API for Lat Long Position\n",
    "    r = requests.get('https://api.weather.gov/points/'+lat+','+long)\n",
    "    json_data = r.json()\n",
    "\n",
    "    # Find Stations in area\n",
    "    url = json_data['properties']['observationStations']\n",
    "\n",
    "    # Select first Station for testing\n",
    "    station_list = requests.get(url).json()['observationStations']\n",
    "    station = station_list[0]\n",
    "    print(rivers_reference['USGS Name'][i])\n",
    "    print('number of stations: ',len(station_list))\n",
    "\n",
    "    # Retrieve Forecast for Lat Long Position\n",
    "    forecast_json = requests.get(json_data['properties']['forecast']).json()\n",
    "    try: \n",
    "        if forecast_json['status'] == 500:\n",
    "            continue\n",
    "    except:\n",
    "        KeyError\n",
    "    forecast = forecast_json['properties']['periods']\n",
    "    Forecast_df = pd.DataFrame(forecast).drop(columns='number')\n",
    "    Forecast_df['Lat'] = lat\n",
    "    Forecast_df['Long'] = long\n",
    "    Forecast_df['Station'] = baseStation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'startTime', 'endTime', 'isDaytime', 'temperature',\n",
       "       'temperatureUnit', 'temperatureTrend', 'windSpeed', 'windDirection',\n",
       "       'icon', 'shortForecast', 'detailedForecast', 'Lat', 'Long', 'Station'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forecast_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSSIAN R A HACIENDA BRIDGE NR GUERNEVILLE CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "NAVARRO R NR NAVARRO CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "NOYO R NR FORT BRAGG CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "SAN LORENZO R A BIG TREES CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "MAD R NR ARCATA CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "PUTAH C NR WINTERS CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "TRUCKEE R A FARAD CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "LITTLE TRUCKEE R AB BOCA RES NR TRUCKEE CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "SMITH R NR CRESCENT CITY CA\n",
      "number of stations:  77\n",
      "number of forecasts:  14\n",
      "\n",
      "1\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "EEL R A FORT SEWARD CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "EEL R A SCOTIA CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "2\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "SAN LORENZO R A SANTA CRUZ CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "HAT C NR HAT CREEK CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "N YUBA R BL GOODYEARS BAR CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "NF AMERICAN R A NORTH FORK DAM CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "PIT R BL PIT NO 1 PH NR FALL RIVER MILLS CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "E WALKER RV NR BRIDGEPORT, CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "E FK CARSON RV BLW MARKLEEVILLE CK NR MARKLEEVILLE\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "TRINITY R A LEWISTON CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "TRINITY R A JUNCTION CITY CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "ROGUE RIVER AT GRANTS PASS, OR\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "ROGUE RIVER NEAR AGNESS, OR\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "NESTUCCA RIVER NEAR BEAVER, OR\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "REDWOOD C A ORICK CA\n",
      "number of stations:  68\n",
      "number of forecasts:  14\n",
      "\n",
      "VAN DUZEN R NR BRIDGEVILLE CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "MATTOLE R NR ETTERSBURG CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "MATTOLE R NR PETROLIA CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "TRINITY R NR BURNT RANCH CA\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "NORTH UMPQUA RIVER AT WINCHESTER, OR\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "NORTH UMPQUA RIVER NEAR IDLEYLD PARK, OR\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "UMPQUA RIVER NEAR ELKTON, OR\n",
      "number of stations:  41\n",
      "number of forecasts:  14\n",
      "\n",
      "YUBA R NR MARYSVILLE CA\n",
      "number of stations:  24\n",
      "number of forecasts:  14\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-952c8f67a213>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m                     ,'elevation(m)','temperature(c)','dewpoint(c)','windDirection(angle)','windSpeed(km/hr)','barometricPressure(Pa)','relativeHumidity(%)']]\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m \u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m full_df[['@id','@type','station','timestamp','rawMessage','textDescription','precipitationLastHour','precipitationLast3Hours','precipitationLast6Hours'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   5269\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5270\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5271\u001b[1;33m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   5406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5407\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5408\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5410\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   5380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5381\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5382\u001b[1;33m             labels, shape = algorithms.factorize(\n\u001b[0m\u001b[0;32m   5383\u001b[0m                 \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSIZE_HINT_LIMIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5384\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m         codes, uniques = factorize_array(\n\u001b[0m\u001b[0;32m    723\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m     uniques, codes = table.factorize(\n\u001b[0m\u001b[0;32m    529\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     )\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "# Parameters\n",
    "startDate = '2022-01-01'\n",
    "endDate = '2022-01-17'\n",
    "\n",
    "rivers_reference = pd.read_csv('C:/Users/Scott/Desktop/Projects/River_Data/RiverReferenceTable.csv')\n",
    "\n",
    "sites = rivers_reference.USGS_ID.tolist()\n",
    "string = ''\n",
    "\n",
    "for i in sites:\n",
    "    string = string+','+str(i)\n",
    "sites=string[1:]\n",
    "\n",
    "# URL to load json of data \n",
    "# Use format=rmd for readable URL\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+sites)\n",
    "r=requests.get(link)\n",
    "Geodata = json.loads(r.text)\n",
    "link = ('https://waterservices.usgs.gov/nwis/iv/?format=json&sites='+sites)\n",
    "r=requests.get(link)\n",
    "Geodata = json.loads(r.text)\n",
    "\n",
    "meta = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(rivers_reference)):\n",
    "    lat = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['latitude'])\n",
    "    long = str(Geodata['value']['timeSeries'][i]['sourceInfo']['geoLocation']['geogLocation']['longitude'])\n",
    "    baseStation = Geodata['value']['timeSeries'][i]['sourceInfo']['siteName']\n",
    "    # Search API for Lat Long Position\n",
    "    r = requests.get('https://api.weather.gov/points/'+lat+','+long)\n",
    "    json_data = r.json()\n",
    "\n",
    "    # Find Stations in area\n",
    "    url = json_data['properties']['observationStations']\n",
    "\n",
    "    # Select first Station for testing\n",
    "    station_list = requests.get(url).json()['observationStations']\n",
    "    station = station_list[0]\n",
    "    print(rivers_reference['USGS Name'][i])\n",
    "    print('number of stations: ',len(station_list))\n",
    "\n",
    "    # Retrieve Forecast for Lat Long Position\n",
    "    forecast_json = requests.get(json_data['properties']['forecast']).json()\n",
    "    try: \n",
    "        if forecast_json['status'] == 500:\n",
    "            continue\n",
    "    except:\n",
    "        KeyError\n",
    "    forecast = forecast_json['properties']['periods']\n",
    "    Forecast_df = pd.DataFrame(forecast).drop(columns='number')\n",
    "    Forecast_df['Lat'] = lat\n",
    "    Forecast_df['Long'] = long\n",
    "    Forecast_df['Station'] = baseStation\n",
    "\n",
    "    full_Forecast = pd.read_csv('Gov_Weather_Forecasts.csv')\n",
    "    full_Forecast = full_Forecast.append(Forecast_df[['name', 'startTime', 'endTime', 'isDaytime', 'temperature',\n",
    "       'temperatureUnit', 'temperatureTrend', 'windSpeed', 'windDirection',\n",
    "       'icon', 'shortForecast', 'detailedForecast', 'Lat', 'Long', 'Station']])\n",
    "       \n",
    "    full_Forecast.drop_duplicates(inplace=True)\n",
    "    full_Forecast.to_csv('Gov_Weather_Forecasts.csv')\n",
    "    \n",
    "    print('number of forecasts: ',len(forecast))\n",
    "    print('')\n",
    "    # Locate first Station during timeframe\n",
    "\n",
    "    observationURL = station+'/observations?start='+startDate+\\\n",
    "        'T00%3A00%3A00-00%3A00&end='+endDate+'T00%3A00%3A00-00%3A00'\n",
    "\n",
    "    payload_meta = pd.DataFrame(requests.get(observationURL).json()['features'])\n",
    "    if payload_meta.shape[0] > 0:\n",
    "        payload_meta['longitude'] = payload_meta.geometry[0]['coordinates'][0]\n",
    "        payload_meta['latitude'] = payload_meta.geometry[0]['coordinates'][1]\n",
    "        payload_meta['base_latitude'] = lat\n",
    "        payload_meta['base_longitude'] = long\n",
    "        payload_meta['USGS Name'] = rivers_reference['USGS Name'][i]\n",
    "        payload = pd.DataFrame(payload_meta.properties.to_dict()).transpose()\n",
    "        payload_meta.drop(columns=['type','properties','geometry'],inplace=True)\n",
    "        meta = meta.append(payload_meta)\n",
    "        \n",
    "        payload['elevation(m)'] = payload['elevation'].apply(lambda x: x['value'])\n",
    "        payload['temperature(c)'] = payload['temperature'].apply(lambda x: x['value'])\n",
    "        payload['dewpoint(c)'] = payload['dewpoint'].apply(lambda x: x['value'])\n",
    "        payload['windDirection(angle)'] = payload['windDirection'].apply(lambda x: x['value'])\n",
    "        payload['windSpeed(km/hr)'] = payload['windSpeed'].apply(lambda x: x['value'])\n",
    "        payload['barometricPressure(Pa)'] = payload['barometricPressure'].apply(lambda x: x['value'])\n",
    "        payload['relativeHumidity(%)'] = payload['relativeHumidity'].apply(lambda x: x['value'])\n",
    "        payload.drop(columns=['elevation','icon', 'presentWeather', 'temperature', 'dewpoint',\n",
    "            'windDirection', 'windSpeed', 'windGust', 'barometricPressure',\n",
    "            'seaLevelPressure', 'visibility', 'maxTemperatureLast24Hours',\n",
    "            'minTemperatureLast24Hours',\n",
    "            'relativeHumidity', 'windChill', 'heatIndex', 'cloudLayers'],inplace=True)\n",
    "        df = df.append(payload)\n",
    "    time.sleep(2)\n",
    "\n",
    "full_df = pd.read_csv('Gov_Weather.csv')\n",
    "full_df = full_df.append(df)\n",
    "full_df = full_df[['@id','@type','station','timestamp','rawMessage','textDescription','precipitationLastHour','precipitationLast3Hours','precipitationLast6Hours'\n",
    "                    ,'elevation(m)','temperature(c)','dewpoint(c)','windDirection(angle)','windSpeed(km/hr)','barometricPressure(Pa)','relativeHumidity(%)']]\n",
    "\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "\n",
    "full_df[['@id','@type','station','timestamp','rawMessage','textDescription','precipitationLastHour','precipitationLast3Hours','precipitationLast6Hours'\n",
    "                    ,'elevation(m)','temperature(c)','dewpoint(c)','windDirection(angle)','windSpeed(km/hr)','barometricPressure(Pa)','relativeHumidity(%)']].to_csv('Gov_Weather.csv',index=False)\n",
    "\n",
    "full_meta = pd.read_csv('Meta_Gov_Weather.csv')\n",
    "full_meta = full_meta.append(meta)\n",
    "full_meta = full_meta[['id','longitude','latitude','base_latitude','base_longitude','USGS Name']]\n",
    "\n",
    "full_meta.drop_duplicates(inplace=True)\n",
    "\n",
    "full_meta[['id','longitude','latitude','base_latitude','base_longitude','USGS Name']].to_csv('Meta_Gov_Weather.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13dba1644c895ef39d34af9edbf5903af097bc92b4f7ba7cfae86f493a62839f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
